{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM 损失函数求梯度\n",
    "参考链接：https://blog.csdn.net/pjia_1008/article/details/66972060\n",
    "    \n",
    "对于第 $i$ 个训练样本来说，SVM 的损失函数为：\n",
    "\n",
    "\\begin{equation*}\n",
    "L_i = \\sum_{j\\neq y_i} \\left[ \\max(0, w_j^Tx_i - w_{y_i}^Tx_i + \\Delta) \\right]\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{c}\n",
    "x_i 表示第 i 个训练样本 flatten 以后的向量  \\\\\n",
    "y_i 表示第 i 个训练样本的标签 \\\\\n",
    "w_j^T 表示第 j 类标签（j\\neq y_i）在 W 权重矩阵中的向量 \\\\\n",
    "w_j^Tx_i 表示第 i 个训练样本在第 j 类标签（j\\neq y_i）上的得分 \\\\\n",
    "w_{y_i}^T 表示第 i 训练样本的标签在 W 权重矩阵中的向量 \\\\\n",
    "w_{y_i}^Tx_i 表示第 i 训练样本在正确分类标签上的得分 \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 $w_{y_i}$ 求偏导：\n",
    "\n",
    "$$\n",
    "\\nabla_{w_{y_i}} L_i = - \\left( \\sum_{j\\neq y_i} \\mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \\Delta > 0) \\right) x_i\n",
    "$$\n",
    "\n",
    "$\\mathbb{1}%$ 表示，当后面的表达式大于 0 时取 1，相当于\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "-x_i,&(w_j^Tx_i - w_{y_i}^Tx_i + \\Delta > 0) \\\\ 0,&(w_j^Tx_i - w_{y_i}^Tx_i + \\Delta <= 0)\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 $w_j$ 求偏导也类似：\n",
    "\n",
    "$$\n",
    "\\nabla_{w_j} L_i = \\mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \\Delta > 0) x_i\n",
    "$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
