{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectionist Temporal Classification Loss(CTC loss)\n",
    "\n",
    "## 问题\n",
    "在语音识别、文字识别领域，输入的数据通常是序列数据，并且我们不知道那一段语音、像素区域对应于 label 中的字符，\n",
    "这个对应过程当然可以用人工的方式来做，但是这种做法费时费力，实际场景中是很低效的。\n",
    "\n",
    "![](https://distill.pub/2017/ctc/assets/handwriting_recognition.svg)\n",
    "![](https://distill.pub/2017/ctc/assets/speech_recognition.svg)\n",
    "\n",
    "对于上述的情况，我们可以使用 Connectionist Temporal Classification (CTC) 来实现原始输入数据和 label 的对齐。\n",
    "\n",
    "定义输入数据为 $\\bf{X}=[x_1, x_2, ..., x_T]$，输出为 $\\bf{Y}=[y_1, y_2, ..., y_U]$，两者有以下关系：\n",
    "- $\\bf X$ 和 $\\bg Y$ 的长度不一定相同\n",
    "- $\\bf X$ 和 $\\bg Y$ 的长度比值不同\n",
    "- $\\bf X$ 和 $\\bg Y$ 两者的对应关系未知\n",
    "\n",
    "CTC 可以克服上面这些问题，最终给出 $\\bf X$ 中每一个元素对应于 $\\bf Y$ 中各元素的概率。\n",
    "\n",
    "**Loss Function:** 对于给定的输入，我们要训练我们的模型，使得输出等于 $Y$ 的概率最大，即求解条件概率函数 $p(Y | X)$ 的最大值。\n",
    "\n",
    "**Inference:** 模型训练好后，给定一个新的输入 $X$，我们可以接如下公式来求输出：\n",
    "\n",
    "$$Y^*=argmax p(Y|X)$$\n",
    "\n",
    "$$Y^* = \\underset{Y}{\\mathrm{argmax}}\\ p(\\Y|X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法\n",
    "先以一个简单的例子为例，输入为一个 6 维的向量，label 为 $Y=[c, a, t]$，假设用对简单的对其方法：一个输入值对应一个字符，然后去掉重复的字符作为最终输出。\n",
    "\n",
    "![](https://distill.pub/2017/ctc/assets/naive_alignment.svg)\n",
    "\n",
    "这种方法有两个问题：\n",
    "- 实际情况中并不是所有输入值都应该对应一个输出的，比如语音识别中可能有不说话的部分，OCR 一块像素中可能是背景\n",
    "- 对于 `hello` 这个单词，永远无法得到正确的结果，去重后只会留下 `helo`\n",
    "\n",
    "为了解决上述的问题，CTC 引入了一个 `blank` 符号，这里用 $ϵ$ 表示。这个符号代表输入中的值不与字符集中的任何一个元素对应，在最后解码时会被移除，下图解释了加入 `blank` 符后的对齐过程：\n",
    "\n",
    "1. 合并连续的相同符号\n",
    "2. 去掉 `blank` 字符。\n",
    "\n",
    "![](https://distill.pub/2017/ctc/assets/ctc_alignment_steps.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "CTC 通常和 RNN 一起使用，RNN 每一个时间步的输出用来计算每一个 label 的概率 $p_t(a_t|\\bf X)$ 。但其实 CTC 也可以和其他结构一起使用，比如 CNN 的输出层接一个全链接层把数据 reshape 成 `[batch_size, time_step, ...]`，也可以把这个数据直接给 CTC。\n",
    "\n",
    "CTC 对齐的整个过程如下：\n",
    "\n",
    "![](https://distill.pub/2017/ctc/assets/full_collapse_from_audio.svg)\n",
    "\n",
    "图中的第三步，需要计算不同输出序列的概率，用暴力的方法求，效率会很低，用**动态规划**来求会快很多。下图是应用动态规划算法的一个示例图，期望的输出为 $Y=[a, b]$，所以有效的起始节点只有两个($ϵ$ 和 $a$)，有效的结束节点也只有两个($ϵ$ 和 $b$)。\n",
    "\n",
    "![](https://distill.pub/2017/ctc/assets/ctc_cost.svg)\n",
    "\n",
    "对于每一个有效路径可以计算出它的概率：\n",
    "$$p(a|X) = \\prod_{t=1}^T p(a_t|X)$$\n",
    "\n",
    "所以对于训练集 $D$，可以通过最小化 negative log-likelihood 方程来求解模型的参数：\n",
    "\n",
    "$$\\sum_{(X, Y) \\in D} -\\log p(Y|X)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (12, 6)\n",
      "Output data shape: (12, 5)\n",
      "[[0.24654511 0.18837589 0.16937668 0.16757465 0.22812766]\n",
      " [0.25443629 0.14992236 0.22945293 0.17240658 0.19378184]\n",
      " [0.24134404 0.17179604 0.23572466 0.12994237 0.22119288]\n",
      " [0.27216255 0.13054313 0.2679252  0.14184499 0.18752413]\n",
      " [0.32558002 0.13485564 0.25228604 0.09743785 0.18984045]\n",
      " [0.23855586 0.14800386 0.23100255 0.17158135 0.21085638]\n",
      " [0.38534786 0.11524603 0.18220093 0.14617864 0.17102655]\n",
      " [0.21867406 0.18511892 0.21305488 0.16472572 0.21842642]\n",
      " [0.29856607 0.13646801 0.27196606 0.11562552 0.17737434]\n",
      " [0.242347   0.14102063 0.21716951 0.2355229  0.16393996]\n",
      " [0.26597326 0.10009752 0.23362892 0.24560198 0.15469832]\n",
      " [0.23337289 0.11918746 0.28540761 0.20197928 0.16005275]]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "使用 softmax 对每一个时间步的值分类，一输入对应 classes 中的一输出\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1111)\n",
    "\n",
    "time_steps = 12\n",
    "vals_dim = 6 # data dim for each time step\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "x = np.random.random([time_steps, vals_dim])\n",
    "w = np.random.random([vals_dim, num_classes])\n",
    "\n",
    "\"\"\"\n",
    "使用 softmax 计算每一个时间步输出值的分类概率\n",
    "\"\"\"\n",
    "def softmax(logits):\n",
    "    max_value = np.max(logits, axis=1, keepdims=True)\n",
    "    exp = np.exp(logits - max_value)\n",
    "    exp_sum = np.sum(exp, axis=1, keepdims=True)\n",
    "    dist = exp / exp_sum\n",
    "    return dist\n",
    "\n",
    "def toy_nw(x):\n",
    "    print(\"Input data shape: {}\".format(x.shape))\n",
    "    y = np.matmul(x, w)\n",
    "    print(\"Output data shape: {}\".format(y.shape))\n",
    "    y = softmax(y)\n",
    "    return y\n",
    "\n",
    "y = toy_nw(x)\n",
    "print(y)\n",
    "raw_rs = np.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 似然计算\n",
    "和大多数有监督学习一样，CTC 使用最大似然标准进行训练。\n",
    "\n",
    "给定输入 $x$，输出 $l$ 的条件概率为：\n",
    "$$\n",
    "p(l|x) =  \\sum_{\\pi \\in B^{-1}(l)} p(\\pi|x)\n",
    "$$\n",
    "\n",
    "其中，$B^{-1}(l)$ 表示了长度为 $T$ 且示经过 $B$ 结果为 $l$ 字符串的集合。\n",
    "\n",
    "**CTC 假设输出的概率是（相对于输入）条件独立的**，因此有：\n",
    "$$p(\\pi|x) = \\prod y^t_{\\pi_t}, \\forall \\pi \\in L^{\\prime T}$$\n",
    "\n",
    "\n",
    "然而，直接按上式我们没有办理有效的计算似然值。下面用动态规划解决似然的计算及梯度计算, 涉及前向算法和后向算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 前向算法\n",
    "\n",
    "在前向及后向计算中，CTC 需要将输出字符串进行扩展。具体的，$(a_1,\\cdots,a_m)$ 每个字符之间及首尾分别插入 blank，即扩展为 $(-, a_1,-,a_2, -,\\cdots,-, a_m,-)$。下面的 $l$ 为原始字符串，$l^\\prime$ 指为扩展后的字符串。\n",
    "\n",
    "定义\n",
    "$$\n",
    "\\alpha_t(s) \\stackrel{def}{=} \\sum_{\\pi \\in N^T: B(\\pi_{1:t}) = l_{1:s}} \\prod_{t^\\prime=1}^t y^t_{\\pi^\\prime}\n",
    "$$\n",
    "\n",
    "显然有，\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\alpha_1(1) = y_b^1,\\\\\n",
    "\\alpha_1(2) = y_{l_1}^1,\\\\\n",
    "\\alpha_1(s) = 0, \\forall s > 2\n",
    "\\end{align}\n",
    "$$\n",
    "根据 $\\alpha$ 的定义，有如下递归关系：\n",
    "$$\n",
    "\\alpha_t(s) = \\{  \\begin{array}{l}\n",
    "(\\alpha_{t-1}(s)+\\alpha_{t-1}(s-1)) y^t_{l^\\prime_s},\\  \\  \\    if\\  l^\\prime_s = b \\ or\\  l_{s-2}^\\prime = l_s^{\\prime}  \\\\\n",
    "(\\alpha_{t-1}(s)+\\alpha_{t-1}(s-1) + \\alpha_{t-1}(s-2)) y^t_{l^\\prime_s} \\ \\ otherwise\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Case 2\n",
    "递归公式中 case 2 是一般的情形。如图所示，$t$ 时刻字符为 $s$ 为 blank 时，它可能由于两种情况扩展而来：\n",
    "1. 重复上一字符，即上个字符也是 a\n",
    "2. 字符发生转换，即上个字符是非 a 的字符，这种情况又分为两种情况\n",
    "  1. 上一字符是 blank\n",
    "  2. a 由非 blank 字符直接跳转而来（$B$） 操作中， blank 最终会被去掉，因此 blank 并不是必须的）。\n",
    "  \n",
    "![](https://distill.pub/2017/ctc/assets/cost_regular.svg)\n",
    "**图2. 前向算法 Case 2 示例【[src](https://distill.pub/2017/ctc/)】**\n",
    "\n",
    "### 1.4.2 Case 1\n",
    "递归公式 case 1 是特殊的情形。\n",
    "如图所示，$t$ 时刻字符为 $s$ 为 blank 时，它只能由于两种情况扩展而来：\n",
    "1. 重复上一字符，即上个字符也是 blank\n",
    "2. 字符发生转换，即上个字符是非 blank 字符。$t$ 时刻字符为 $s$ 为非 blank 时，类似于 case 2，但是这时两个相同字符之间的 blank 不能省略（否则无法区分\"aa\"和\"a\"），因此，也只有两种跳转情况。\n",
    "\n",
    "![](https://distill.pub/2017/ctc/assets/cost_no_skip.svg)\n",
    "**图3. 前向算法 Case 1 【[src](https://distill.pub/2017/ctc/)】**\n",
    "\n",
    "我们可以利用动态规划计算所有 $\\alpha$ 的值，算法时间和空间复杂度为 $O(T * L)$。\n",
    "\n",
    "似然的计算只涉及乘加运算，因此，CTC 的似然是可导的，可以尝试 tensorflow 或 pytorch 等具有自动求导功能的工具自动进行梯度计算。下面介绍如何手动高效的计算梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.46545113e-01   1.67574654e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  6.27300235e-02   7.13969720e-02   4.26370730e-02   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.51395174e-02   1.74287803e-02   2.75214373e-02   5.54036251e-03\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  4.12040964e-03   4.61964998e-03   1.22337658e-02   4.68965079e-03\n",
      "    1.50787918e-03   1.03895167e-03   0.00000000e+00]\n",
      " [  1.34152305e-03   8.51612635e-04   5.48713543e-03   1.64898136e-03\n",
      "    2.01779193e-03   1.37377693e-03   3.38261905e-04]\n",
      " [  3.20028190e-04   3.76301179e-04   1.51214552e-03   1.22442454e-03\n",
      "    8.74730268e-04   1.06283215e-03   4.08416903e-04]\n",
      " [  1.23322177e-04   1.01788478e-04   7.27708889e-04   4.00028082e-04\n",
      "    8.08904808e-04   5.40783712e-04   5.66942671e-04]\n",
      " [  2.69673617e-05   3.70815141e-05   1.81389560e-04   1.85767281e-04\n",
      "    2.64362267e-04   3.82184328e-04   2.42231029e-04]\n",
      " [  8.05153930e-06   7.40568461e-06   6.52280509e-05   4.24527009e-05\n",
      "    1.34393412e-04   1.47631121e-04   1.86429242e-04]\n",
      " [  1.95126637e-06   3.64053019e-06   1.76025677e-05   2.53612828e-05\n",
      "    4.28581244e-05   5.31947855e-05   8.09585256e-05]\n",
      " [  5.18984675e-07   1.37335633e-06   5.65009596e-06   1.05520069e-05\n",
      "    1.81445380e-05   1.87825719e-05   3.56811933e-05]\n",
      " [  1.21116956e-07   3.82213679e-07   1.63908339e-06   3.27248912e-06\n",
      "    6.69699576e-06   7.59916314e-06   1.27103665e-05]]\n"
     ]
    }
   ],
   "source": [
    "def forward(y, labels):\n",
    "    T, V = y.shape\n",
    "    L = len(labels)\n",
    "    alpha = np.zeros([T, L])\n",
    "\n",
    "    # init\n",
    "    alpha[0, 0] = y[0, labels[0]]\n",
    "    alpha[0, 1] = y[0, labels[1]]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        for i in range(L):\n",
    "            s = labels[i]\n",
    "            \n",
    "            a = alpha[t - 1, i] \n",
    "            if i - 1 >= 0:\n",
    "                a += alpha[t - 1, i - 1]\n",
    "            if i - 2 >= 0 and s != 0 and s != labels[i - 2]:\n",
    "                a += alpha[t - 1, i - 2]\n",
    "                \n",
    "            alpha[t, i] = a * y[t, s]\n",
    "            \n",
    "    return alpha\n",
    "\n",
    "labels = [0, 3, 0, 3, 0, 4, 0]  # 0 for blank\n",
    "alpha = forward(y, labels)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后可以得到似然 $p(l|x) = \\alpha_T(|l^\\prime|) + \\alpha_T(|l^\\prime|-1)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.81811271177e-06\n"
     ]
    }
   ],
   "source": [
    "p = alpha[-1, labels[-1]] + alpha[-1, labels[-2]]\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 解码\n",
    "训练的 $N_w$ 可以用来预测新的样本输入对应的输出字符串，这涉及到解码。\n",
    "按照最大似然准则，最优的解码结果为：\n",
    "$$\n",
    "h(x) = \\underset{l \\in L^{\\le T}}{\\mathrm{argmax}}\\ p(l|x)\n",
    "$$\n",
    "\n",
    "然而，上式不存在已知的高效解法。下面介绍几种实用的近似解码方法。\n",
    "\n",
    "## 3.1 贪心搜索 （greedy search）\n",
    "虽然 $p(l|x)$ 难以有效的计算，但是由于 CTC 的独立性假设，对于某个具体的字符串 $\\pi$（去 blank 前），确容易计算：\n",
    "$$\n",
    "p(\\pi|x) = \\prod_{k=1}^T p(\\pi_k|x)\n",
    "$$\n",
    "\n",
    "因此，我们放弃寻找使 $p(l|x)$ 最大的字符串，退而寻找一个使 $p(\\pi|x)$ 最大的字符串，即：\n",
    "\n",
    "$$\n",
    "h(x) \\approx B(\\pi^\\star)\n",
    "$$\n",
    "其中，\n",
    "$$\n",
    "\\pi^\\star = \\underset{\\pi \\in N^T}{\\mathrm{argmax}}\\ p(\\pi|x)\n",
    "$$\n",
    "\n",
    "简化后，解码过程（构造 $\\pi^\\star$）变得非常简单（基于独立性假设）： 在每个时刻输出概率最大的字符:\n",
    "$$\n",
    "\\pi^\\star = cat_{t=1}^T(\\underset{s \\in L^\\prime}{\\mathrm{argmax}}\\ y^t_s)\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (20, 6)\n",
      "[1 3 5 5 5 5 1 5 3 4 4 3 0 4 5 0 3 1 3 3]\n",
      "[1, 3, 5, 1, 5, 3, 4, 3, 4, 5, 3, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "def remove_blank(labels, blank=0):\n",
    "    new_labels = []\n",
    "    \n",
    "    # combine duplicate\n",
    "    previous = None\n",
    "    for l in labels:\n",
    "        if l != previous:\n",
    "            new_labels.append(l)\n",
    "            previous = l\n",
    "            \n",
    "    # remove blank     \n",
    "    new_labels = [l for l in new_labels if l != blank]\n",
    "    \n",
    "    return new_labels\n",
    "\n",
    "def insert_blank(labels, blank=0):\n",
    "    new_labels = [blank]\n",
    "    for l in labels:\n",
    "        new_labels += [l, blank]\n",
    "    return new_labels\n",
    "\n",
    "def greedy_decode(y, blank=0):\n",
    "    raw_rs = np.argmax(y, axis=1)\n",
    "    rs = remove_blank(raw_rs, blank)\n",
    "    return raw_rs, rs\n",
    "\n",
    "np.random.seed(1111)\n",
    "y = softmax(np.random.random([20, 6]))\n",
    "print(\"Input shape: {}\".format(y.shape))\n",
    "rr, rs = greedy_decode(y)\n",
    "print(rr)\n",
    "print(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 束搜索（Beam Search）\n",
    "显然，贪心搜索的性能非常受限。例如，它不能给出除最优路径之外的其他其优路径。很多时候，如果我们能拿到 nbest 的路径，后续可以利用其他信息来进一步优化搜索的结果。束搜索能近似找出 top 最优的若干条路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 1, 5, 3, 4, 3, 4, 5, 3, 1, 3] -29.261797539205567\n",
      "[1, 3, 5, 1, 5, 3, 4, 3, 3, 5, 3, 1, 3] -29.279020152518033\n",
      "[1, 3, 5, 1, 5, 3, 4, 2, 3, 4, 5, 3, 1, 3] -29.300726142201842\n",
      "[1, 5, 1, 5, 3, 4, 3, 4, 5, 3, 1, 3] -29.310307014773972\n",
      "[1, 3, 5, 1, 5, 3, 4, 2, 3, 3, 5, 3, 1, 3] -29.31794875551431\n",
      "[1, 5, 1, 5, 3, 4, 3, 3, 5, 3, 1, 3] -29.327529628086438\n",
      "[1, 3, 5, 1, 5, 4, 3, 4, 5, 3, 1, 3] -29.331572723457334\n",
      "[1, 3, 5, 5, 1, 5, 3, 4, 3, 4, 5, 3, 1, 3] -29.33263180992451\n",
      "[1, 3, 5, 4, 1, 5, 3, 4, 3, 4, 5, 3, 1, 3] -29.334649090836038\n",
      "[1, 3, 5, 1, 5, 3, 4, 3, 4, 5, 3, 1, 3] -29.33969505198154\n"
     ]
    }
   ],
   "source": [
    "def beam_decode(y, beam_size=10):\n",
    "    T, V = y.shape\n",
    "    log_y = np.log(y)\n",
    "    \n",
    "    beam = [([], 0)]\n",
    "    for t in range(T):  # for every timestep\n",
    "        new_beam = []\n",
    "        for prefix, score in beam:\n",
    "            for i in range(V):  # for every state\n",
    "                new_prefix = prefix + [i]\n",
    "                new_score = score + log_y[t, i]\n",
    "                \n",
    "                new_beam.append((new_prefix, new_score))\n",
    "                \n",
    "        # top beam_size\n",
    "        new_beam.sort(key=lambda x: x[1], reverse=True)\n",
    "        beam = new_beam[:beam_size]\n",
    "        \n",
    "    return beam\n",
    "    \n",
    "np.random.seed(1111)\n",
    "y = softmax(np.random.random([20, 6]))\n",
    "beam = beam_decode(y, beam_size=100)\n",
    "for string, score in beam[:10]:\n",
    "    print(remove_blank(string), score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 前缀束搜索（Prefix Beam Search）\n",
    "直接的束搜索的一个问题是，在保存的 top N 条路径中，可能存在多条实际上是同一结果（经过去重复、去 blank 操作）。这减少了搜索结果的多样性。下面介绍的前缀搜索方法，在搜索过程中不断的合并相同的前缀[2]。参考 [gist](https://gist.github.com/awni/56369a90d03953e370f3964c826ed4b0)，前缀束搜索实现如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 5, 4, 1, 3, 4, 5, 2, 3], (-18.189863809114193, -17.613677981426175))\n",
      "([1, 5, 4, 5, 3, 4, 5, 2, 3], (-18.19636512622969, -17.621013424585406))\n",
      "([1, 5, 4, 1, 3, 4, 5, 1, 3], (-18.317018960331531, -17.666629973270073))\n",
      "([1, 5, 4, 5, 3, 4, 5, 1, 3], (-18.323388267369936, -17.674125139073176))\n",
      "([1, 5, 4, 1, 3, 4, 3, 2, 3], (-18.415808498759556, -17.862744326248826))\n",
      "([1, 5, 4, 1, 3, 4, 3, 5, 3], (-18.366422766638632, -17.898463479112884))\n",
      "([1, 5, 4, 5, 3, 4, 3, 2, 3], (-18.42224294936932, -17.870025672291458))\n",
      "([1, 5, 4, 5, 3, 4, 3, 5, 3], (-18.372199113900191, -17.905130493229173))\n",
      "([1, 5, 4, 1, 3, 4, 5, 4, 3], (-18.457066311773847, -17.880630315602037))\n",
      "([1, 5, 4, 5, 3, 4, 5, 4, 3], (-18.462614293487096, -17.88759583852546))\n",
      "([1, 5, 4, 1, 3, 4, 5, 3, 2], (-18.458941701567706, -17.951422824358747))\n",
      "([1, 5, 4, 5, 3, 4, 5, 3, 2], (-18.464527031120184, -17.958629487208658))\n",
      "([1, 5, 4, 1, 3, 4, 3, 1, 3], (-18.540857550725587, -17.920589910093689))\n",
      "([1, 5, 4, 5, 3, 4, 3, 1, 3], (-18.547146092248852, -17.928030266681613))\n",
      "([1, 5, 4, 1, 3, 4, 5, 3, 2, 3], (-19.325467801462263, -17.689203224408899))\n",
      "([1, 5, 4, 5, 3, 4, 5, 3, 2, 3], (-19.328748799764973, -17.694105969982637))\n",
      "([1, 5, 4, 1, 3, 4, 5, 3, 4], (-18.79699026165903, -17.945090229238392))\n",
      "([1, 5, 4, 5, 3, 4, 5, 3, 4], (-18.803585534273239, -17.95258394264377))\n",
      "([1, 5, 4, 3, 4, 3, 5, 2, 3], (-19.181531846082809, -17.859420073785095))\n",
      "([1, 5, 4, 1, 3, 4, 5, 2, 3, 2], (-19.439349296385199, -17.884502168470895))\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def prefix_beam_decode(y, beam_size=10, blank=0):\n",
    "    T, V = y.shape\n",
    "    log_y = np.log(y)\n",
    "    \n",
    "    beam = [(tuple(), (0, ninf))]  # blank, non-blank\n",
    "    for t in range(T):  # for every timestep\n",
    "        new_beam = defaultdict(lambda : (ninf, ninf))\n",
    "             \n",
    "        for prefix, (p_b, p_nb) in beam:\n",
    "            for i in range(V):  # for every state\n",
    "                p = log_y[t, i]\n",
    "                \n",
    "                if i == blank:  # propose a blank\n",
    "                    new_p_b, new_p_nb = new_beam[prefix]\n",
    "                    new_p_b = logsumexp(new_p_b, p_b + p, p_nb + p)\n",
    "                    new_beam[prefix] = (new_p_b, new_p_nb)\n",
    "                    continue\n",
    "                else:  # extend with non-blank\n",
    "                    end_t = prefix[-1] if prefix else None\n",
    "                    \n",
    "                    # exntend current prefix\n",
    "                    new_prefix = prefix + (i,)\n",
    "                    new_p_b, new_p_nb = new_beam[new_prefix]\n",
    "                    if i != end_t:\n",
    "                        new_p_nb = logsumexp(new_p_nb, p_b + p, p_nb + p)\n",
    "                    else:\n",
    "                        new_p_nb = logsumexp(new_p_nb, p_b + p)\n",
    "                    new_beam[new_prefix] = (new_p_b, new_p_nb)\n",
    "                    \n",
    "                    # keep current prefix\n",
    "                    if i == end_t:\n",
    "                        new_p_b, new_p_nb = new_beam[prefix]\n",
    "                        new_p_nb = logsumexp(new_p_nb, p_nb + p)\n",
    "                        new_beam[prefix] = (new_p_b, new_p_nb)\n",
    "                \n",
    "        # top beam_size\n",
    "        beam = sorted(new_beam.items(), key=lambda x : logsumexp(*x[1]), reverse=True)\n",
    "        beam = beam[:beam_size]\n",
    "        \n",
    "    return beam\n",
    "\n",
    "np.random.seed(1111)\n",
    "y = softmax(np.random.random([20, 6]))\n",
    "beam = prefix_beam_decode(y, beam_size=100)\n",
    "for string, score in beam[:20]:\n",
    "    print(remove_blank(string), score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 其他解码方法\n",
    "上述介绍了基本解码方法。实际中，搜索过程可以接合额外的信息，提高搜索的准确度（例如在语音识别任务中，加入语言模型得分信息, [前缀搜索+语言模型](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/decoders/decoders_deprecated.py\n",
    ")）。\n",
    "\n",
    "本质上，CTC 只是一个训练准则。训练完成后，$N_w$ 输出一系列概率分布，这点和常规基于交叉熵准则训练的模型完全一致。因此，特定应用领域常规的解码也可以经过一定修改用来 CTC 的解码。例如在语音识别任务中，利用 CTC 训练的声学模型可以无缝融入原来的 WFST 的解码器中[5]（e.g. 参见 [EESEN](https://github.com/srvk/eesen)）。\n",
    "\n",
    "此外，[1] 给出了一种利用 CTC 顶峰特点的启发式搜索方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 工具\n",
    "\n",
    "[warp-ctc](https://github.com/baidu-research/warp-ctc) 是百度开源的基于 CPU 和 GPU 的高效并行实现。warp-ctc 自身提供 C 语言接口，对于流利的机器学习工具（[torch](https://github.com/baidu-research/warp-ctc/tree/master/torch_binding)、 [pytorch](https://github.com/SeanNaren/deepspeech.pytorch) 和 [tensorflow](https://github.com/baidu-research/warp-ctc/tree/master/tensorflow_binding)、[chainer](https://github.com/jheymann85/chainer_ctc)）都有相应的接口绑定。\n",
    "\n",
    "[cudnn 7](https://developer.nvidia.com/cudnn) 以后开始提供 CTC 支持。\n",
    "\n",
    "Tensorflow 也原生支持 [CTC loss](https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss)，及 greedy 和 beam search 解码器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结\n",
    "1. CTC 可以建模无对齐信息的多对多序列问题（输入长度不小于输出），如语音识别、连续字符识别 [3,4]。\n",
    "2. CTC 不需要输入与输出的对齐信息，可以实现端到端的训练。\n",
    "3. CTC 在 loss 的计算上，利用了整个 labels 序列的全局信息，某种意义上相对逐帧计算损失的方法，\"更加区分性\"。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. Graves et al. [Connectionist Temporal Classification : Labelling Unsegmented Sequence Data with Recurrent Neural Networks](ftp://ftp.idsia.ch/pub/juergen/icml2006.pdf).\n",
    "2. Hannun et al. [First-Pass Large Vocabulary Continuous Speech Recognition using Bi-Directional Recurrent DNNs](https://arxiv.org/abs/1408.2873).\n",
    "3. Graves et al. [Towards End-To-End Speech Recognition with Recurrent Neural Networks](http://jmlr.org/proceedings/papers/v32/graves14.pdf).\n",
    "4. Liwicki et al. [A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks](https://www.cs.toronto.edu/~graves/icdar_2007.pdf).\n",
    "5. Zenkel et al. [Comparison of Decoding Strategies for CTC Acoustic Models](https://arxiv.org/abs/1708.004469).\n",
    "5. Huannun. [Sequence Modeling with CTC](https://distill.pub/2017/ctc/).\n",
    "\n",
    "参考：\n",
    "- https://distill.pub/2017/ctc/\n",
    "- https://medium.com/corti-ai/ctc-networks-and-language-models-prefix-beam-search-explained-c11d1ee23306\n",
    "- https://github.com/DingKe/ml-tutorial/blob/master/ctc/CTC.ipynb\n",
    "- http://hongbomin.com/2017/06/23/beam-search/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
